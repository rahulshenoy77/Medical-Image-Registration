{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Quantization levels\n",
    "# 8 bit int can represent for 256 levels\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import labelreg.helpers as helper\n",
    "import labelreg.networks as network\n",
    "import labelreg.utils as util\n",
    "import labelreg.losses as loss\n",
    "NUM_OF_LEVEL = 256\n",
    "\n",
    "def get_quantization_levels(model_meta, model_dir):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # load the checkpoint\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.import_meta_graph(model_meta)\n",
    "        saver.restore(sess, model_dir)\n",
    "        graph = tf.get_default_graph()\n",
    "        all_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        quant_levels = {}\n",
    "        for v in all_vars:\n",
    "            # quantize only network variables\n",
    "            if ('fcn' in v.name) and ('Adam' not in v.name):\n",
    "                level_name = v.name\n",
    "                v_numpy = sess.run(v)\n",
    "                v_numpy_shape = v_numpy.shape\n",
    "                v_numpy_flatten = v_numpy.flatten()\n",
    "                min_np = v_numpy.min()\n",
    "                max_np = v_numpy.max()\n",
    "                gap = (max_np - min_np) / (NUM_OF_LEVEL - 1)\n",
    "                quant_levels[level_name] = np.asarray([(min_np + x * gap) for x in range(NUM_OF_LEVEL)])\n",
    "    return quant_levels\n",
    "    \n",
    "# one method to do quantization\n",
    "def strategy_1(v_numpy):\n",
    "    v_numpy_shape = v_numpy.shape\n",
    "    v_numpy_flatten = v_numpy.flatten()\n",
    "    min_np = v_numpy.min()\n",
    "    max_np = v_numpy.max()\n",
    "    gap = (max_np - min_np) / (NUM_OF_LEVEL - 1)\n",
    "    levels = np.asarray([(min_np + x * gap) for x in range(NUM_OF_LEVEL)])\n",
    "    for i in range(len(v_numpy_flatten)):\n",
    "        v_numpy_flatten[i] = min(levels, key=lambda x : abs(x-v_numpy_flatten[i]))\n",
    "    v_numpy = v_numpy_flatten.reshape(v_numpy_shape)\n",
    "    return v_numpy\n",
    "\n",
    "\n",
    "def quantize_one_variable(sess, v,levels):\n",
    "    v_numpy = sess.run(v)\n",
    "    v_numpy_shape = v_numpy.shape\n",
    "    v_numpy_flatten = v_numpy.flatten()\n",
    "    for i in range(len(v_numpy_flatten)):\n",
    "        v_numpy_flatten[i] = min(levels, key=lambda x : abs(x-v_numpy_flatten[i]))\n",
    "    v_numpy = v_numpy_flatten.reshape(v_numpy_shape)\n",
    "    new_v = v_numpy\n",
    "    assign_op = v.assign(new_v)\n",
    "    return assign_op\n",
    "\n",
    "def quantize_model(model_meta,model_dir,target_dir,quant_levels):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # load the checkpoint\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.import_meta_graph(model_meta)\n",
    "        saver.restore(sess, model_dir)\n",
    "        graph = tf.get_default_graph()\n",
    "        all_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        update_operation = []\n",
    "        for v in all_vars:\n",
    "            # quantize only network variables\n",
    "            if ('fcn' in v.name) and ('Adam' not in v.name):\n",
    "                level_name = v.name\n",
    "                levels = quant_levels[level_name]\n",
    "                update_operation.append(quantize_one_variable(sess, v,levels))\n",
    "        _ = sess.run(update_operation)\n",
    "        # save the qunatized checkpoint\n",
    "        saver.save(sess, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\pruned_model_retrain2\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\pruned_model_retrain2\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#Quantize Model\n",
    "model_dir = r\"C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\pruned_model_retrain2\\model.ckpt\"\n",
    "model_meta = r\"C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\pruned_model_retrain2\\model.ckpt.meta\"\n",
    "target_dir = r\"C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\quantized_model2\\model.ckpt\"\n",
    "QUANT_LEVELS = get_quantization_levels(model_meta,model_dir)\n",
    "quantize_model(model_meta,model_dir,target_dir,QUANT_LEVELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading default config file in: C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\config_demo.ini.\n",
      "\n",
      "[Network]: network_type: local\n",
      "[Inference]: file_model_saved: C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\quantized_model2\\model.ckpt\n",
      "[Inference]: dir_moving_image: C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\test\\moving_images\n",
      "[Inference]: dir_fixed_image: C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\test\\fixed_images\n",
      "[Inference]: dir_save: C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\inference_results\\Quantized2_results\n",
      "[Inference]: dir_moving_label: C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\test\\moving_labels\n",
      "[Inference]: dir_fixed_label: C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\test\\fixed_labels\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\rahul\\OneDrive\\Desktop\\Courses\\ECE209as\\Final Project\\label-reg-master\\labelreg\\ibsr v2\\data_final\\quantized_model2\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# inference quantized model\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import labelreg.helpers as helper\n",
    "import labelreg.networks as network\n",
    "import labelreg.apps as app\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# 0 - get configs\n",
    "config = helper.ConfigParser(sys.argv, 'inference')\n",
    "\n",
    "# 1 - images to register\n",
    "reader_moving_image, reader_fixed_image, _, _ = helper.get_data_readers(config['Inference']['dir_moving_image'],\n",
    "                                                                        config['Inference']['dir_fixed_image'])\n",
    "\n",
    "# 2 - graph\n",
    "# network for predicting ddf only\n",
    "ph_moving_image = tf.placeholder(tf.float32, [reader_moving_image.num_data]+reader_moving_image.data_shape+[1])\n",
    "ph_fixed_image = tf.placeholder(tf.float32, [reader_fixed_image.num_data]+reader_fixed_image.data_shape+[1])\n",
    "\n",
    "reg_net = network.build_network(network_type=config['Network']['network_type'],\n",
    "                                minibatch_size=reader_moving_image.num_data,\n",
    "                                image_moving=ph_moving_image,\n",
    "                                image_fixed=ph_fixed_image)\n",
    "\n",
    "# restore the trained weights\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, config['Inference']['file_model_saved'])\n",
    "\n",
    "\n",
    "# 3 - compute ddf\n",
    "testFeed = {ph_moving_image: reader_moving_image.get_data(),\n",
    "            ph_fixed_image: reader_fixed_image.get_data()}\n",
    "ddf = sess.run(reg_net.ddf, feed_dict=testFeed)\n",
    "helper.write_images(ddf, config['Inference']['dir_save'], 'ddf')\n",
    "\n",
    "# warp the test images\n",
    "warped_images = app.warp_volumes_by_ddf(reader_moving_image.get_data(), ddf)\n",
    "helper.write_images(warped_images, config['Inference']['dir_save'], 'warped_image')\n",
    "\n",
    "# warp test labels of gland segmentation, i.e. label_indices=0\n",
    "if config['Inference']['dir_moving_label']:\n",
    "    data_moving_label = helper.DataReader(config['Inference']['dir_moving_label'],labelr=True).get_data(label_indices=[1])\n",
    "    warped_labels = app.warp_volumes_by_ddf(data_moving_label, ddf)\n",
    "    helper.write_images(warped_labels, config['Inference']['dir_save'], 'warped_label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
